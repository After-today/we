{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 正则表达式"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.常用的元字符：<br/>\n",
    ".\t匹配除换行符以外的任意字符<br/>\n",
    "\\w\t匹配字母或数字或下划线或汉字<br/>\n",
    "\\s\t匹配任意的空白符<br/>\n",
    "\\d\t匹配数字<br/>\n",
    "\\W 匹配任意不是字母，数字，下划线，汉字的字符<br/>\n",
    "\\S 匹配任意不是空白符的字符<br/>\n",
    "\\D 匹配任意非数字的字符<br/>\n",
    "例子：\\S+匹配不包含空白符的字符串。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.注释<br/>\n",
    "(?<=    断言要匹配的文本的前缀<br/>\n",
    ")      前缀结束<br/>\n",
    "(?=    断言要匹配的文本的后缀<br/>\n",
    "）     后缀结束<br/>\n",
    ".*      匹配任意文本"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.贪婪与懒惰<br/>\n",
    "贪婪：当正则表达式中包含能接受重复的限定符时，通常的行为是（在使整个表达式能得到匹配的前提下）<br/>\n",
    "匹配尽可能多字符。以这个表达式为例：a.*b，<br>\n",
    "它将会匹配最长的以a开始，以b结束的字符串。如果用它来搜索aabab的话，<br/>\n",
    "它会匹配整个字符串aabab。这被称为贪婪匹配。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "懒惰：前面给出的限定符都可以被转化为懒惰匹配模式，只要在它后面加上一个问号?。<br/>\n",
    "这样.*?就意味着匹配任意数量的重复，但是在能使整个匹配<br/>\n",
    "成功的前提下使用最少的重复,懒惰模式下上例取出的是aab。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os  \n",
    "from functools import reduce\n",
    "from win32com import client as wc \n",
    "import codecs  \n",
    "import glob  \n",
    "import pandas as pd \n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def char2int1(s):      #将字符型转换成浮点型\n",
    "    return {'0':0,'1':1,'2':2,'3':3,'4':4,'5':5,'6':6,'7':7,'8':8,'9':9,'十':10,'百':100,'千':1000,'万':10000}[s]\n",
    "\n",
    "f=0\n",
    "def mulit_int1(x,y):\n",
    "    if y<10:\n",
    "        f1= 10*x+y\n",
    "    else:\n",
    "        f1=x*y  \n",
    "    return f1\n",
    "        \n",
    "def str2int1(s):\n",
    "    if s.find('.')==-1:#不是浮点数\n",
    "        return reduce(mulit_int1,map(char2int1,s))\n",
    "    else:#是浮点数\n",
    "        s1=s.split('.')\n",
    "        s2int=reduce(mulit_int1,map(char2int1,s1[0])) #整数部分\n",
    " \n",
    "        s2float=reduce(mulit_int1,map(char2int1,s1[1]))*0.1**len(s1[1]) #小数部分 \n",
    "        return(s2int+s2float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://blog.csdn.net/xsj_blog/article/details/52034527 #reduce函数的讲解\n",
    "https://www.liaoxuefeng.com/wiki/001434446689867b27157e896e74d51a89c25cc8b43bdb3000/001435119854495d29b9b3d7028477a96ed74db95032675000 #map函数讲解"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"test.txt\")# 返回一个文件对象  \n",
    "line = f.readline()\n",
    "n=1\n",
    "while line:                    \n",
    "    b='line'+str(n)+\" \"+line          #逐行读取并在行首加上“line行数 ”\n",
    "    n +=1\n",
    "    slcxs=re.findall(r\"(?<=line11 )\\w+\",b)#查找一审二审\n",
    "    if slcxs==[]:\n",
    "        pass\n",
    "    else:\n",
    "        slcx=slcxs \n",
    "    wsbhs=re.findall(r\"(?<=line9 )\\D.*?\\D\\w+\",b)\n",
    "    if wsbhs==[]:\n",
    "        pass\n",
    "    else:\n",
    "        wsbh=wsbhs   #print(wsbh)#查找文书编号\n",
    "    line = f.readline()\n",
    "f.close()\n",
    "f = open(\"test.txt\")\n",
    "c=f.read()\n",
    "titles=re.findall(r\"(?<=)\\w.*?案\",c)\n",
    "title=titles[0]\n",
    "sjnfs=re.findall(r\"(?<=)二.*?年\",c)\n",
    "sjnf=sjnfs[-1]\n",
    "d=re.findall(r\"(?<=)\\w.*现已审理\",c) \n",
    "ywsbhs=re.findall(r\"(?<=不服).*?号\",str(d))#查找文书编号\n",
    "ywsbh=re.findall(r\"(?<=)（2.*?号\",str(ywsbhs))#查找原文书编号\n",
    "ssqq=re.findall(r\"(?<=)判令.*\",c) #查找诉讼请求\n",
    "jjss1=re.findall(r\"(?<=经济损失).*?元\",str(ssqq))\n",
    "jjss2=re.findall(r\"(?<=)\\d.*?元\",str(jjss1))\n",
    "jjss3=[x.strip('元') for x in jjss2]\n",
    "sjjss=[str2int1(i) for i in jjss3]\n",
    "sfgps=re.findall(r\"(?<=驳回上诉)\\D.*\",c) #是否改判\n",
    "if sfgps==[]:\n",
    "    sfgp='是'\n",
    "else:\n",
    "    sfgp='否'\n",
    "f.close()\n",
    "f = open(\"test.txt\")\n",
    "e=[line.strip() for line in f.readlines()]\n",
    "h=re.findall(r\"(?<=民事判决书).*?现已审理\",str(e))\n",
    "l=re.findall(r\"(?<=)\\w.* \",str(h))  \n",
    "yuangaos=re.findall(r\"(?<=原告\\D)\\w.*?。\",str(l))\n",
    "yuangao=[x.strip('。') for x in yuangaos]\n",
    "fypjs=re.findall(r\"(?<=人民共和国).*?。\",str(e))   #查找法院判决\n",
    "fypjs1=re.findall(r\"(?<=)判决.*?。\",str(fypjs))   #查找法院判决\n",
    "fypj1=fypjs1\n",
    "fypjs2=re.findall(r\"(?<=)判决如下.*?。\",str(fypjs))   #查找法院判决\n",
    "fypj2=fypjs2\n",
    "pplys=re.findall(r\"(?<=)院认为.*?人民共和\",str(e)) #判赔理由\n",
    "if len(pplys)>0:\n",
    "    pply1=pplys[0]\n",
    "else:\n",
    "    pply1=='无'\n",
    "if len(pplys)>1:\n",
    "    pply2=pplys[-1]\n",
    "else:\n",
    "    pply2='无'\n",
    "f.close()\n",
    "data={'wsbh':wsbh, 'ywsbh':ywsbh,'sjnf':sjnf, 'yuangao':yuangao,'ssqq':ssqq,\n",
    "      'sjjss':sjjss,'pply1':pply1,'pply2':pply2,'fypj1':fypj1,'fypj2':fypj2,\n",
    "      'slcx':slcx,'title':title}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fypj1': ['判决：一、广州市千钧网络科技有限公司于判决发生法律效力之日起十日内赔偿北京橙天嘉禾影视制作有限公司经济损失及合理开支共计人民币15000元；二、驳回北京橙天嘉禾影视制作有限公司的其他诉讼请求。',\n",
       "  \"判决如下：', '驳回上诉，维持原判。\"],\n",
       " 'fypj2': [\"判决如下：', '驳回上诉，维持原判。\"],\n",
       " 'pply1': \"院认为，依照我国著作权法的规定，电影作品和以类似摄制电影的方法创作的作品的著作权由制片者享有，当事人提供的涉及著作权的底稿、原件、合法出版物、著作权登记证书、认证机构出具的证明、取得权利的合同等，可以作为证据。香港影业协会系国家版权局指定的认证机构，其出具的《版权证明书》已办理相应的公证转递手续，其证明效力应予确认。该证明书载明，橙天嘉禾公司经授权取得涉案影片《2012我爱HK喜上加囍》在中国（不包括台湾、香港及澳门）的电影发行放映权、信息网络传播权、音像制品复制发行权等，其中信息网络传播权期限自2012年4月5日至同年6月30日止。在无相反证据予以推翻的情况下，该院认定橙天嘉禾公司就该影片享有信息网络传播权，其主体适格。千钧公司所称橙天嘉禾公司享有的独家信息网络传播权有瑕疵、不具备本案诉讼主体资格的抗辩缺乏依据，该院对此不予采纳。', '橙天嘉禾公司就涉案影片于2012年6月在大陆地区上映的主张已提供相应的海报、联和院线网、电影网网页等证据，上述证据显示涉案影片的出品方与《发行权证明书》、DVD出版物封套所载一致，上映日期与《发行权证明书》载明的电影发行放映权期限能相印证，该院对此应予采信。浙江省杭州市钱塘公证处出具的（2012）浙杭钱证民字第2735号公证书显示，涉案作品系网站注册会员“mablle117”上传，因此，千钧公司在本案中仅需承担提供信息存储空间的网络服务提供者的法律责任。对于此类网络服务提供者侵权责任承担与否的认定，应当根据《信息网络传播权保护条例》的相关规定并结合具体案情进行综合判断。', '本案中，涉案视频明确标识影片名称，视频播放内容完整，系经专业制作的电影作品。该视频虽为网站的注册会员上传，但以日常经验法则判断，对于此类视频内容完整之电影作品，一般情况下权利人不会轻易上传至互联网提供给公众免费观看或下载，且视频发布时涉案电影尚未在大陆地区上映，若该视频被广泛传播，必将对电影发行收益产生极大的影响。千钧公司作为专门从事视频分享网站的经营者，已被相关影视作品权利人多次起诉至法院，其应该意识到在注册用户上传的作品中会存在侵权视频问题，对于即将上映的电影作品，应当能够尽到合理的注意义务，采取各种措施避免侵权行为的发生。涉案视频存放于“电影”类别之下，千钧公司完全有条件、有能力核实其权利来源，避免侵权视频的传播，却怠于行使该义务，放任侵权行为的发生。因此，对于涉案视频被上传至其经营的网站中进行传播，千钧公司主观上存在过错，其行为客观上为他人实施侵权行为提供了帮助，不应适用《信息网络传播权保护条例》中免除赔偿责任之规定，依法应承担赔偿损失的民事责任。鉴于橙天嘉禾公司所享有的信息网络传播权期限现已届满，其主张千钧公司停止侵权已无法律依据，对此该院不予支持。', '关于赔偿损失的数额。橙天嘉禾公司未就其实际损失进行举证，千钧公司就涉案侵权视频的播放而取得的收益在客观上也无法确定，故该院综合考虑涉案作品的类型、市场影响、上映档期、千钧公司传播侵权视频的持续时间、播放次数、主观过错程度、涉案网站的经营性质、规模，以及橙天嘉禾公司所主张合理开支的必要性和合理性等因素，酌情确定千钧公司的赔偿数额。', '综上所述，依照《中华人民共和\",\n",
       " 'pply2': '院认为：根据《中华人民共和',\n",
       " 'sjjss': [100000],\n",
       " 'sjnf': '二Ｏ一三年',\n",
       " 'slcx': ['二审'],\n",
       " 'ssqq': ['判令：1、依法撤销原审判决，改判千钧公司赔偿经济损失10万元，并承担橙天嘉禾公司为制止侵权所支付的合理费用1万元；2、千钧公司承担本案一审、二审的全部诉讼费用。'],\n",
       " 'title': '北京橙天嘉禾影视制作有限公司与广州市千钧网络科技有限公司侵害作品信息网络传播权纠纷上诉案',\n",
       " 'wsbh': ['(2013)穗中法知民终字第670号'],\n",
       " 'yuangao': [],\n",
       " 'ywsbh': ['（2012）穗天法知民初字第1294号']}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "这是一个复杂的关系图，人与人之间都有多个相联系的对象，然后你通过<br/>\n",
    "一个人层层传递可以找到与自己完全不相关的人。 相比于那种圆形图，这<br/>\n",
    "个中间的环节多了很多。比如有一个人发了一个微博，和他相关的人转发，<br/>\n",
    "转发的人又带动了很多人转发，消息就传播开了。而最重要的人就是你通过<br/>\n",
    "他能和所有人联系起来，并且总共所用步数最少。通过找到这个人最重要的<br/>\n",
    "联系人，就可以以最快的速度将这个人的信息发布出去。运用到商业领域，<br/>\n",
    "也就能够帮助企业更好地进行品牌的宣传"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['LCF_graph', 'adjacency_graph', 'barabasi_albert_graph', 'barbell_graph', 'binomial_graph', 'bull_graph', 'caveman_graph', 'chordal_cycle_graph', 'chvatal_graph', 'circulant_graph', 'circular_ladder_graph', 'complete_bipartite_graph', 'complete_graph', 'complete_multipartite_graph', 'connected_caveman_graph', 'connected_watts_strogatz_graph', 'cubical_graph', 'cycle_graph', 'cytoscape_graph', 'davis_southern_women_graph', 'dense_gnm_random_graph', 'desargues_graph', 'diamond_graph', 'digraph', 'directed_havel_hakimi_graph', 'dodecahedral_graph', 'dorogovtsev_goltsev_mendes_graph', 'duplication_divergence_graph', 'edge_subgraph', 'ego_graph', 'empty_graph', 'erdos_renyi_graph', 'expected_degree_graph', 'extended_barabasi_albert_graph', 'fast_gnp_random_graph', 'florentine_families_graph', 'frucht_graph', 'gaussian_random_partition_graph', 'general_random_intersection_graph', 'geographical_threshold_graph', 'gn_graph', 'gnc_graph', 'gnm_random_graph', 'gnp_random_graph', 'gnr_graph', 'graph', 'grid_2d_graph', 'grid_graph', 'havel_hakimi_graph', 'heawood_graph', 'hexagonal_lattice_graph', 'hoffman_singleton_graph', 'house_graph', 'house_x_graph', 'hypercube_graph', 'icosahedral_graph', 'induced_subgraph', 'inverse_line_graph', 'is_directed_acyclic_graph', 'jit_graph', 'joint_degree_graph', 'json_graph', 'k_random_intersection_graph', 'karate_club_graph', 'kl_connected_subgraph', 'krackhardt_kite_graph', 'ladder_graph', 'line_graph', 'lollipop_graph', 'make_max_clique_graph', 'make_small_graph', 'margulis_gabber_galil_graph', 'moebius_kantor_graph', 'multidigraph', 'multigraph', 'mycielski_graph', 'navigable_small_world_graph', 'newman_watts_strogatz_graph', 'node_link_graph', 'null_graph', 'nx_agraph', 'octahedral_graph', 'pappus_graph', 'partial_duplication_graph', 'path_graph', 'petersen_graph', 'planted_partition_graph', 'powerlaw_cluster_graph', 'projected_graph', 'quotient_graph', 'random_clustered_graph', 'random_degree_sequence_graph', 'random_geometric_graph', 'random_k_out_graph', 'random_kernel_graph', 'random_partition_graph', 'random_regular_graph', 'random_shell_graph', 'relabel_gexf_graph', 'relaxed_caveman_graph', 'scale_free_graph', 'sedgewick_maze_graph', 'soft_random_geometric_graph', 'star_graph', 'stochastic_graph', 'subgraph', 'tetrahedral_graph', 'thresholded_random_geometric_graph', 'to_networkx_graph', 'tree_graph', 'triad_graph', 'triangular_lattice_graph', 'trivial_graph', 'truncated_cube_graph', 'truncated_tetrahedron_graph', 'turan_graph', 'tutte_graph', 'uniform_random_intersection_graph', 'watts_strogatz_graph', 'waxman_graph', 'wheel_graph', 'windmill_graph']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x91034e0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "# NetwordX所的供的示例图\n",
    "print([s for s in dir(nx) if s.endswith(\"graph\")])\n",
    "G = nx.davis_southern_women_graph()\n",
    "# plt.figure(1)\n",
    "# plt.hist(list(nx.degree(G).values()))\n",
    "plt.figure(2)\n",
    "pos = nx.spring_layout(G)\n",
    "nx.draw(G, node_size=9)\n",
    "nx.draw_networkx_labels(G, pos)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "节点的度，即此节点在网络中的与其相连接邻居节点的数目。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Python组会",
   "toc_cell": false,
   "toc_position": {
    "height": "512px",
    "left": "1139px",
    "top": "107.13px",
    "width": "322px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
